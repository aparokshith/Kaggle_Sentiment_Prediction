{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import words\n",
    "cv = CountVectorizer(binary=True)\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"sa-emotions/train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n",
       "       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(tes):\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "    REPLACE_U_NAME = re.compile(\"@[\\S]+\")\n",
    "    REPLACE_DIGITS = re.compile(\"\\d\")\n",
    "    REPLACE_W_SPACE = re.compile(\"_\")\n",
    "    tes[\"content\"] = tes[\"content\"].str.replace(REPLACE_NO_SPACE, '')\n",
    "    tes[\"content\"] = tes[\"content\"].str.replace(REPLACE_U_NAME,'')\n",
    "    tes[\"content\"] = tes[\"content\"].str.replace(REPLACE_DIGITS,'')\n",
    "    tes[\"content\"] = tes[\"content\"].str.replace(REPLACE_W_SPACE,'')\n",
    "    tes[\"content\"] = tes[\"content\"].str.lower()\n",
    "    return tes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = cleaner(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin = df_train.loc[(df_train['sentiment'] == 'sadness') | (df_train['sentiment'] == 'happiness')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sadness      4828\n",
       "happiness    2986\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bin.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: `Series.plot()` should not be called with positional arguments, only keyword arguments. The order of positional arguments will change in the future. Use `Series.plot(kind='bar')` instead of `Series.plot('bar',)`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_bin['sentiment'].value_counts().plot('bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_bin[\"content\"], df_bin[\"sentiment\"], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train)\n",
    "X_train_vec = cv.transform(X_train)\n",
    "X_test_vec = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sadness      3203\n",
       "happiness    2032\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.703373400542846\n",
      "Accuracy for C=0.05: 0.7576580069794494\n",
      "Accuracy for C=0.25: 0.7782086079875921\n",
      "Accuracy for C=0.5: 0.7793718495540908\n",
      "Accuracy for C=1: 0.7793718495540908\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]: #Inverse of regularization strength, Smaller the C stronger the regularization\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train_vec, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_test, lr.predict(X_test_vec))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.7793718495540908\n"
     ]
    }
   ],
   "source": [
    "#Best performance is when C is set to 1\n",
    "final_model = LogisticRegression(C=1)\n",
    "final_model.fit(X_train_vec, y_train)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_model.predict(X_test_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sad', 3.2421112161581)\n",
      "('sucks', 2.3738325318168516)\n",
      "('miss', 2.2994959632227587)\n",
      "('sick', 2.157765111119589)\n",
      "('missing', 2.100194432015421)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_sad in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print(best_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('thanks', -2.4901581059599387)\n",
      "('great', -2.0534266939648176)\n",
      "('happy', -2.0307366109327436)\n",
      "('glad', -2.0051014441034214)\n",
      "('welcome', -1.9233627254380306)\n"
     ]
    }
   ],
   "source": [
    "for best_happy in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print(best_happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lreg_CV = Pipeline([('vect', cv), ('clf', LogisticRegression(C=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lreg_CV = Lreg_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7793718495540908"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = Lreg_CV.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.73      0.64      0.68       954\n",
      "     sadness       0.80      0.86      0.83      1625\n",
      "\n",
      "    accuracy                           0.78      2579\n",
      "   macro avg       0.77      0.75      0.76      2579\n",
      "weighted avg       0.78      0.78      0.78      2579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC_CV = Pipeline([('vect', CountVectorizer()), ('clf', LinearSVC(random_state=0, tol=1e-5)), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC_CV = LSVC_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765412950756107"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = LSVC_CV.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.69      0.66      0.67       954\n",
      "     sadness       0.80      0.83      0.82      1625\n",
      "\n",
      "    accuracy                           0.77      2579\n",
      "   macro avg       0.75      0.74      0.75      2579\n",
      "weighted avg       0.76      0.77      0.76      2579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF = Pipeline([(\"vect\", cv), (\"RandomForestClassifier\", RandomForestClassifier(n_estimators=100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF = randomF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7576580069794494"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = randomF.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.76      0.50      0.60       954\n",
      "     sadness       0.76      0.91      0.83      1625\n",
      "\n",
      "    accuracy                           0.76      2579\n",
      "   macro avg       0.76      0.70      0.71      2579\n",
      "weighted avg       0.76      0.76      0.74      2579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraT = Pipeline([(\"vect\",cv), (\"ExtraTrees\",ExtraTreesClassifier(n_estimators=100, random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraT = extraT.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7669639395114386"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = extraT.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.76      0.54      0.63       954\n",
      "     sadness       0.77      0.90      0.83      1625\n",
      "\n",
      "    accuracy                           0.77      2579\n",
      "   macro avg       0.76      0.72      0.73      2579\n",
      "weighted avg       0.77      0.77      0.76      2579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the 7814 contents is represented by 1883 features (TF-IDF score of unigrams and bigrams)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1, 2), \n",
    "                        stop_words='english')\n",
    "\n",
    "# We transform each complaint into a vector\n",
    "features = tfidf.fit_transform(df_bin.content).toarray()\n",
    "\n",
    "labels = df_bin.sentiment\n",
    "\n",
    "print(\"Each of the %d contents is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing(features,labels):\n",
    "    models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    ]\n",
    "\n",
    "    # 5 Cross-validation\n",
    "    CV = 5\n",
    "    cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "    entries = []\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "        for fold_idx, accuracy in enumerate(accuracies):\n",
    "            entries.append((model_name, fold_idx, accuracy))\n",
    "\n",
    "    cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "    mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "    std_accuracy = cv_df.groupby('model_name').accuracy.std()\n",
    "\n",
    "    acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n",
    "              ignore_index=True)\n",
    "    acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.759147</td>\n",
       "      <td>0.041509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.769641</td>\n",
       "      <td>0.051783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.755949</td>\n",
       "      <td>0.048864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.627079</td>\n",
       "      <td>0.006379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Accuracy  Standard deviation\n",
       "model_name                                               \n",
       "LinearSVC                    0.759147            0.041509\n",
       "LogisticRegression           0.769641            0.051783\n",
       "MultinomialNB                0.755949            0.048864\n",
       "RandomForestClassifier       0.627079            0.006379"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu = model_testing(features, labels)\n",
    "accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining CountVec and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(df_bin[\"content\"])\n",
    "count_vec_feat = cv.transform(df_bin[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7814, 11863) (7814, 1883)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7814, 13746)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(count_vec_feat.shape,features.shape)\n",
    "X = scipy.sparse.hstack([count_vec_feat, features])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7814,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.767977</td>\n",
       "      <td>0.047066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.784101</td>\n",
       "      <td>0.051985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.775144</td>\n",
       "      <td>0.062294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.623880</td>\n",
       "      <td>0.005565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Accuracy  Standard deviation\n",
       "model_name                                               \n",
       "LinearSVC                    0.767977            0.047066\n",
       "LogisticRegression           0.784101            0.051985\n",
       "MultinomialNB                0.775144            0.062294\n",
       "RandomForestClassifier       0.623880            0.005565"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu = model_testing(X, labels)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sadness</td>\n",
       "      <td>i should be sleep but im not thinking about an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sadness</td>\n",
       "      <td>charlene my love i miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sadness</td>\n",
       "      <td>im sorry  at least its friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content\n",
       "1   sadness  layin n bed with a headache  ughhhhwaitin on y...\n",
       "2   sadness                      funeral ceremonygloomy friday\n",
       "6   sadness  i should be sleep but im not thinking about an...\n",
       "8   sadness                        charlene my love i miss you\n",
       "9   sadness                      im sorry  at least its friday"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        [layin, n, bed, headache, ughhhhwaitin, call]\n",
       "2                    [funeral, ceremonygloomy, friday]\n",
       "6    [sleep, im, thinking, old, friend, want, hes, ...\n",
       "8                               [charlene, love, miss]\n",
       "9                           [im, sorry, least, friday]\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_stop_removal = df_bin[\"content\"].apply(lambda x: [item for item in x.split() if item not in stop])\n",
    "w2v_stop_removal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7814"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_stop_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we went to the capital of Great Britain', 'it was amazing', 'I hate']\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"we went to the capital of Great Britain\",\"it was amazing\",\"I hate\"]\n",
    "sent = [x for x in sentence if x not in stop]\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-f8aa7bcdab71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vectors' is not defined"
     ]
    }
   ],
   "source": [
    "feats = [sum(x) for x in vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        print(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute similarity with no input %s ['suuure']\n",
      "cannot compute similarity with no input %s ['roughnight']\n",
      "cannot compute similarity with no input %s ['grrrrrrrrrrrrrrrrrrrrrrrr']\n",
      "cannot compute similarity with no input %s ['--', 'yeahhh', 'wasnt', 'thereeeeeeeeeee']\n",
      "cannot compute similarity with no input %s ['yeaaaahh']\n",
      "cannot compute similarity with no input %s ['hallooo', 'bayernhallooo', 'stau']\n",
      "cannot compute similarity with no input %s ['awee']\n",
      "cannot compute similarity with no input %s ['suchatease']\n",
      "cannot compute similarity with no input %s []\n",
      "cannot compute similarity with no input %s []\n",
      "cannot compute similarity with no input %s ['sadface']\n",
      "cannot compute similarity with no input %s ['shareeee']\n",
      "cannot compute similarity with no input %s ['michelleeeeeeeeeeeemybelleeeeeeeeeeeeeeeeee', '*snif', 'snif*']\n",
      "cannot compute similarity with no input %s []\n",
      "cannot compute similarity with no input %s ['goooooodmorning']\n",
      "cannot compute similarity with no input %s ['helloooo']\n",
      "cannot compute similarity with no input %s ['chilliin']\n",
      "cannot compute similarity with no input %s ['hahaaaha']\n",
      "cannot compute similarity with no input %s ['tear*']\n",
      "cannot compute similarity with no input %s ['goodmorning']\n",
      "cannot compute similarity with no input %s ['http//twitpiccom/vfcx', 'awesomeeeeee']\n",
      "cannot compute similarity with no input %s ['goodmorning']\n",
      "cannot compute similarity with no input %s ['yeaaa']\n"
     ]
    }
   ],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "train_tokenized = df_bin.apply(lambda r: w2v_tokenize_text(r['content']), axis=1).values\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "check_train = [w2v_tokenize_text(x) for x in sentence]\n",
    "check_train_word_average = word_averaging_list(wv,check_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 300\n",
      "3 300\n",
      "1 300\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(check_train)):\n",
    "    print(len(check_train[i]),len(check_train_word_average[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = train_test_split(df_bin, test_size=0.3, random_state = 42)\n",
    "\n",
    "# test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['content']), axis=1).values\n",
    "# train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['content']), axis=1).values\n",
    "\n",
    "# X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "# X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n",
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n",
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n",
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n",
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.777576</td>\n",
       "      <td>0.057653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.775143</td>\n",
       "      <td>0.058740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.695162</td>\n",
       "      <td>0.034481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Accuracy  Standard deviation\n",
       "model_name                                               \n",
       "LinearSVC                    0.777576            0.057653\n",
       "LogisticRegression           0.775143            0.058740\n",
       "MultinomialNB                     NaN                 NaN\n",
       "RandomForestClassifier       0.695162            0.034481"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu = model_testing(X_train_word_average, labels)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.map({'sadness': 0, 'happiness': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train_word_average,labels, test_size= 0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5860, 300) (1954, 300)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(300,100,200), max_iter=500, alpha=0.0001,learning_rate = 'constant',\n",
    "                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69030234\n",
      "Iteration 2, loss = 0.67826681\n",
      "Iteration 3, loss = 0.67104863\n",
      "Iteration 4, loss = 0.66749659\n",
      "Iteration 5, loss = 0.66562903\n",
      "Iteration 6, loss = 0.66446040\n",
      "Iteration 7, loss = 0.66383775\n",
      "Iteration 8, loss = 0.66338956\n",
      "Iteration 9, loss = 0.66308738\n",
      "Iteration 10, loss = 0.66284606\n",
      "Iteration 11, loss = 0.66264452\n",
      "Iteration 12, loss = 0.66246963\n",
      "Iteration 13, loss = 0.66229043\n",
      "Iteration 14, loss = 0.66210005\n",
      "Iteration 15, loss = 0.66192714\n",
      "Iteration 16, loss = 0.66177271\n",
      "Iteration 17, loss = 0.66159649\n",
      "Iteration 18, loss = 0.66141088\n",
      "Iteration 19, loss = 0.66123044\n",
      "Iteration 20, loss = 0.66106100\n",
      "Iteration 21, loss = 0.66087466\n",
      "Iteration 22, loss = 0.66068576\n",
      "Iteration 23, loss = 0.66048853\n",
      "Iteration 24, loss = 0.66028341\n",
      "Iteration 25, loss = 0.66009086\n",
      "Iteration 26, loss = 0.65988177\n",
      "Iteration 27, loss = 0.65967059\n",
      "Iteration 28, loss = 0.65946331\n",
      "Iteration 29, loss = 0.65926822\n",
      "Iteration 30, loss = 0.65903048\n",
      "Iteration 31, loss = 0.65880593\n",
      "Iteration 32, loss = 0.65856853\n",
      "Iteration 33, loss = 0.65835490\n",
      "Iteration 34, loss = 0.65809004\n",
      "Iteration 35, loss = 0.65785351\n",
      "Iteration 36, loss = 0.65760014\n",
      "Iteration 37, loss = 0.65732132\n",
      "Iteration 38, loss = 0.65705840\n",
      "Iteration 39, loss = 0.65677740\n",
      "Iteration 40, loss = 0.65649963\n",
      "Iteration 41, loss = 0.65622970\n",
      "Iteration 42, loss = 0.65592556\n",
      "Iteration 43, loss = 0.65560560\n",
      "Iteration 44, loss = 0.65528515\n",
      "Iteration 45, loss = 0.65495103\n",
      "Iteration 46, loss = 0.65468044\n",
      "Iteration 47, loss = 0.65427468\n",
      "Iteration 48, loss = 0.65393736\n",
      "Iteration 49, loss = 0.65357163\n",
      "Iteration 50, loss = 0.65322657\n",
      "Iteration 51, loss = 0.65277787\n",
      "Iteration 52, loss = 0.65238655\n",
      "Iteration 53, loss = 0.65198655\n",
      "Iteration 54, loss = 0.65155255\n",
      "Iteration 55, loss = 0.65108037\n",
      "Iteration 56, loss = 0.65061740\n",
      "Iteration 57, loss = 0.65015133\n",
      "Iteration 58, loss = 0.64964415\n",
      "Iteration 59, loss = 0.64912626\n",
      "Iteration 60, loss = 0.64858109\n",
      "Iteration 61, loss = 0.64800550\n",
      "Iteration 62, loss = 0.64743071\n",
      "Iteration 63, loss = 0.64683757\n",
      "Iteration 64, loss = 0.64617882\n",
      "Iteration 65, loss = 0.64551899\n",
      "Iteration 66, loss = 0.64489641\n",
      "Iteration 67, loss = 0.64416662\n",
      "Iteration 68, loss = 0.64344764\n",
      "Iteration 69, loss = 0.64274040\n",
      "Iteration 70, loss = 0.64193950\n",
      "Iteration 71, loss = 0.64117134\n",
      "Iteration 72, loss = 0.64036236\n",
      "Iteration 73, loss = 0.63956859\n",
      "Iteration 74, loss = 0.63866140\n",
      "Iteration 75, loss = 0.63772772\n",
      "Iteration 76, loss = 0.63678090\n",
      "Iteration 77, loss = 0.63583685\n",
      "Iteration 78, loss = 0.63479283\n",
      "Iteration 79, loss = 0.63374964\n",
      "Iteration 80, loss = 0.63260837\n",
      "Iteration 81, loss = 0.63150621\n",
      "Iteration 82, loss = 0.63030632\n",
      "Iteration 83, loss = 0.62912614\n",
      "Iteration 84, loss = 0.62785467\n",
      "Iteration 85, loss = 0.62653252\n",
      "Iteration 86, loss = 0.62513890\n",
      "Iteration 87, loss = 0.62375176\n",
      "Iteration 88, loss = 0.62230091\n",
      "Iteration 89, loss = 0.62088508\n",
      "Iteration 90, loss = 0.61926516\n",
      "Iteration 91, loss = 0.61763958\n",
      "Iteration 92, loss = 0.61605154\n",
      "Iteration 93, loss = 0.61439096\n",
      "Iteration 94, loss = 0.61265887\n",
      "Iteration 95, loss = 0.61081252\n",
      "Iteration 96, loss = 0.60899214\n",
      "Iteration 97, loss = 0.60708351\n",
      "Iteration 98, loss = 0.60509379\n",
      "Iteration 99, loss = 0.60310731\n",
      "Iteration 100, loss = 0.60106416\n",
      "Iteration 101, loss = 0.59898913\n",
      "Iteration 102, loss = 0.59689991\n",
      "Iteration 103, loss = 0.59472704\n",
      "Iteration 104, loss = 0.59236578\n",
      "Iteration 105, loss = 0.59009766\n",
      "Iteration 106, loss = 0.58773065\n",
      "Iteration 107, loss = 0.58541059\n",
      "Iteration 108, loss = 0.58292269\n",
      "Iteration 109, loss = 0.58044763\n",
      "Iteration 110, loss = 0.57817665\n",
      "Iteration 111, loss = 0.57544939\n",
      "Iteration 112, loss = 0.57286616\n",
      "Iteration 113, loss = 0.57019585\n",
      "Iteration 114, loss = 0.56768341\n",
      "Iteration 115, loss = 0.56484762\n",
      "Iteration 116, loss = 0.56218886\n",
      "Iteration 117, loss = 0.55955741\n",
      "Iteration 118, loss = 0.55687258\n",
      "Iteration 119, loss = 0.55421984\n",
      "Iteration 120, loss = 0.55148242\n",
      "Iteration 121, loss = 0.54888627\n",
      "Iteration 122, loss = 0.54610402\n",
      "Iteration 123, loss = 0.54352546\n",
      "Iteration 124, loss = 0.54082096\n",
      "Iteration 125, loss = 0.53834279\n",
      "Iteration 126, loss = 0.53557780\n",
      "Iteration 127, loss = 0.53308090\n",
      "Iteration 128, loss = 0.53052457\n",
      "Iteration 129, loss = 0.52804679\n",
      "Iteration 130, loss = 0.52545415\n",
      "Iteration 131, loss = 0.52299566\n",
      "Iteration 132, loss = 0.52068111\n",
      "Iteration 133, loss = 0.51831878\n",
      "Iteration 134, loss = 0.51591776\n",
      "Iteration 135, loss = 0.51410613\n",
      "Iteration 136, loss = 0.51146729\n",
      "Iteration 137, loss = 0.50917751\n",
      "Iteration 138, loss = 0.50728698\n",
      "Iteration 139, loss = 0.50521440\n",
      "Iteration 140, loss = 0.50313479\n",
      "Iteration 141, loss = 0.50127407\n",
      "Iteration 142, loss = 0.49931610\n",
      "Iteration 143, loss = 0.49728202\n",
      "Iteration 144, loss = 0.49557247\n",
      "Iteration 145, loss = 0.49367380\n",
      "Iteration 146, loss = 0.49245423\n",
      "Iteration 147, loss = 0.49076861\n",
      "Iteration 148, loss = 0.48919947\n",
      "Iteration 149, loss = 0.48740240\n",
      "Iteration 150, loss = 0.48583094\n",
      "Iteration 151, loss = 0.48470512\n",
      "Iteration 152, loss = 0.48323760\n",
      "Iteration 153, loss = 0.48162761\n",
      "Iteration 154, loss = 0.48033843\n",
      "Iteration 155, loss = 0.47973840\n",
      "Iteration 156, loss = 0.47876121\n",
      "Iteration 157, loss = 0.47684634\n",
      "Iteration 158, loss = 0.47579988\n",
      "Iteration 159, loss = 0.47497881\n",
      "Iteration 160, loss = 0.47328189\n",
      "Iteration 161, loss = 0.47235296\n",
      "Iteration 162, loss = 0.47129595\n",
      "Iteration 163, loss = 0.47030200\n",
      "Iteration 164, loss = 0.46952836\n",
      "Iteration 165, loss = 0.46824031\n",
      "Iteration 166, loss = 0.46716045\n",
      "Iteration 167, loss = 0.46661435\n",
      "Iteration 168, loss = 0.46539618\n",
      "Iteration 169, loss = 0.46512595\n",
      "Iteration 170, loss = 0.46395112\n",
      "Iteration 171, loss = 0.46302171\n",
      "Iteration 172, loss = 0.46299060\n",
      "Iteration 173, loss = 0.46148802\n",
      "Iteration 174, loss = 0.46072578\n",
      "Iteration 175, loss = 0.46036977\n",
      "Iteration 176, loss = 0.45942164\n",
      "Iteration 177, loss = 0.45838306\n",
      "Iteration 178, loss = 0.45802305\n",
      "Iteration 179, loss = 0.45695273\n",
      "Iteration 180, loss = 0.45653620\n",
      "Iteration 181, loss = 0.45619877\n",
      "Iteration 182, loss = 0.45509179\n",
      "Iteration 183, loss = 0.45427824\n",
      "Iteration 184, loss = 0.45433601\n",
      "Iteration 185, loss = 0.45329090\n",
      "Iteration 186, loss = 0.45282018\n",
      "Iteration 187, loss = 0.45196762\n",
      "Iteration 188, loss = 0.45121789\n",
      "Iteration 189, loss = 0.45093904\n",
      "Iteration 190, loss = 0.45019122\n",
      "Iteration 191, loss = 0.44982579\n",
      "Iteration 192, loss = 0.44923943\n",
      "Iteration 193, loss = 0.44947032\n",
      "Iteration 194, loss = 0.44811257\n",
      "Iteration 195, loss = 0.44790314\n",
      "Iteration 196, loss = 0.44717820\n",
      "Iteration 197, loss = 0.44643744\n",
      "Iteration 198, loss = 0.44666069\n",
      "Iteration 199, loss = 0.44575807\n",
      "Iteration 200, loss = 0.44551863\n",
      "Iteration 201, loss = 0.44501115\n",
      "Iteration 202, loss = 0.44392789\n",
      "Iteration 203, loss = 0.44482879\n",
      "Iteration 204, loss = 0.44318207\n",
      "Iteration 205, loss = 0.44343301\n",
      "Iteration 206, loss = 0.44257357\n",
      "Iteration 207, loss = 0.44240084\n",
      "Iteration 208, loss = 0.44153646\n",
      "Iteration 209, loss = 0.44132117\n",
      "Iteration 210, loss = 0.44086432\n",
      "Iteration 211, loss = 0.44055686\n",
      "Iteration 212, loss = 0.44023651\n",
      "Iteration 213, loss = 0.43970831\n",
      "Iteration 214, loss = 0.43996447\n",
      "Iteration 215, loss = 0.43892211\n",
      "Iteration 216, loss = 0.43885890\n",
      "Iteration 217, loss = 0.43850628\n",
      "Iteration 218, loss = 0.43805767\n",
      "Iteration 219, loss = 0.43837791\n",
      "Iteration 220, loss = 0.43709826\n",
      "Iteration 221, loss = 0.43713866\n",
      "Iteration 222, loss = 0.43649376\n",
      "Iteration 223, loss = 0.43593565\n",
      "Iteration 224, loss = 0.43577892\n",
      "Iteration 225, loss = 0.43580108\n",
      "Iteration 226, loss = 0.43537205\n",
      "Iteration 227, loss = 0.43511968\n",
      "Iteration 228, loss = 0.43462665\n",
      "Iteration 229, loss = 0.43415931\n",
      "Iteration 230, loss = 0.43370485\n",
      "Iteration 231, loss = 0.43367918\n",
      "Iteration 232, loss = 0.43310303\n",
      "Iteration 233, loss = 0.43303332\n",
      "Iteration 234, loss = 0.43317997\n",
      "Iteration 235, loss = 0.43285537\n",
      "Iteration 236, loss = 0.43208441\n",
      "Iteration 237, loss = 0.43225469\n",
      "Iteration 238, loss = 0.43169015\n",
      "Iteration 239, loss = 0.43135955\n",
      "Iteration 240, loss = 0.43165173\n",
      "Iteration 241, loss = 0.43113883\n",
      "Iteration 242, loss = 0.43054437\n",
      "Iteration 243, loss = 0.43098371\n",
      "Iteration 244, loss = 0.42992794\n",
      "Iteration 245, loss = 0.42990570\n",
      "Iteration 246, loss = 0.42955111\n",
      "Iteration 247, loss = 0.42966686\n",
      "Iteration 248, loss = 0.42885717\n",
      "Iteration 249, loss = 0.42881841\n",
      "Iteration 250, loss = 0.42859402\n",
      "Iteration 251, loss = 0.42832124\n",
      "Iteration 252, loss = 0.42794536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.42801407\n",
      "Iteration 254, loss = 0.42716758\n",
      "Iteration 255, loss = 0.42759009\n",
      "Iteration 256, loss = 0.42661386\n",
      "Iteration 257, loss = 0.42677737\n",
      "Iteration 258, loss = 0.42667313\n",
      "Iteration 259, loss = 0.42664656\n",
      "Iteration 260, loss = 0.42628260\n",
      "Iteration 261, loss = 0.42578775\n",
      "Iteration 262, loss = 0.42704398\n",
      "Iteration 263, loss = 0.42519647\n",
      "Iteration 264, loss = 0.42509793\n",
      "Iteration 265, loss = 0.42577287\n",
      "Iteration 266, loss = 0.42440482\n",
      "Iteration 267, loss = 0.42540399\n",
      "Iteration 268, loss = 0.42362276\n",
      "Iteration 269, loss = 0.42344119\n",
      "Iteration 270, loss = 0.42390057\n",
      "Iteration 271, loss = 0.42338717\n",
      "Iteration 272, loss = 0.42346907\n",
      "Iteration 273, loss = 0.42309452\n",
      "Iteration 274, loss = 0.42280005\n",
      "Iteration 275, loss = 0.42254504\n",
      "Iteration 276, loss = 0.42284259\n",
      "Iteration 277, loss = 0.42244052\n",
      "Iteration 278, loss = 0.42260735\n",
      "Iteration 279, loss = 0.42212013\n",
      "Iteration 280, loss = 0.42182743\n",
      "Iteration 281, loss = 0.42147422\n",
      "Iteration 282, loss = 0.42133124\n",
      "Iteration 283, loss = 0.42180776\n",
      "Iteration 284, loss = 0.42071202\n",
      "Iteration 285, loss = 0.42161872\n",
      "Iteration 286, loss = 0.42053511\n",
      "Iteration 287, loss = 0.42017480\n",
      "Iteration 288, loss = 0.41999588\n",
      "Iteration 289, loss = 0.42036443\n",
      "Iteration 290, loss = 0.41981436\n",
      "Iteration 291, loss = 0.41926297\n",
      "Iteration 292, loss = 0.41926009\n",
      "Iteration 293, loss = 0.41906302\n",
      "Iteration 294, loss = 0.41924292\n",
      "Iteration 295, loss = 0.41927986\n",
      "Iteration 296, loss = 0.41861871\n",
      "Iteration 297, loss = 0.41868477\n",
      "Iteration 298, loss = 0.41798257\n",
      "Iteration 299, loss = 0.41818079\n",
      "Iteration 300, loss = 0.41775503\n",
      "Iteration 301, loss = 0.41763982\n",
      "Iteration 302, loss = 0.41725310\n",
      "Iteration 303, loss = 0.41754481\n",
      "Iteration 304, loss = 0.41733303\n",
      "Iteration 305, loss = 0.41681184\n",
      "Iteration 306, loss = 0.41755875\n",
      "Iteration 307, loss = 0.41662881\n",
      "Iteration 308, loss = 0.41688758\n",
      "Iteration 309, loss = 0.41631011\n",
      "Iteration 310, loss = 0.41589114\n",
      "Iteration 311, loss = 0.41656464\n",
      "Iteration 312, loss = 0.41599717\n",
      "Iteration 313, loss = 0.41611156\n",
      "Iteration 314, loss = 0.41674507\n",
      "Iteration 315, loss = 0.41546704\n",
      "Iteration 316, loss = 0.41529639\n",
      "Iteration 317, loss = 0.41494388\n",
      "Iteration 318, loss = 0.41473307\n",
      "Iteration 319, loss = 0.41453958\n",
      "Iteration 320, loss = 0.41505834\n",
      "Iteration 321, loss = 0.41441603\n",
      "Iteration 322, loss = 0.41443270\n",
      "Iteration 323, loss = 0.41398274\n",
      "Iteration 324, loss = 0.41312440\n",
      "Iteration 325, loss = 0.41331634\n",
      "Iteration 326, loss = 0.41361786\n",
      "Iteration 327, loss = 0.41315460\n",
      "Iteration 328, loss = 0.41379683\n",
      "Iteration 329, loss = 0.41303215\n",
      "Iteration 330, loss = 0.41283232\n",
      "Iteration 331, loss = 0.41269129\n",
      "Iteration 332, loss = 0.41211859\n",
      "Iteration 333, loss = 0.41269718\n",
      "Iteration 334, loss = 0.41247857\n",
      "Iteration 335, loss = 0.41220103\n",
      "Iteration 336, loss = 0.41185338\n",
      "Iteration 337, loss = 0.41135992\n",
      "Iteration 338, loss = 0.41194150\n",
      "Iteration 339, loss = 0.41177318\n",
      "Iteration 340, loss = 0.41130533\n",
      "Iteration 341, loss = 0.41110136\n",
      "Iteration 342, loss = 0.41062839\n",
      "Iteration 343, loss = 0.41056275\n",
      "Iteration 344, loss = 0.41061037\n",
      "Iteration 345, loss = 0.41049314\n",
      "Iteration 346, loss = 0.41042174\n",
      "Iteration 347, loss = 0.41031764\n",
      "Iteration 348, loss = 0.41029525\n",
      "Iteration 349, loss = 0.40955085\n",
      "Iteration 350, loss = 0.40985086\n",
      "Iteration 351, loss = 0.40975561\n",
      "Iteration 352, loss = 0.40991271\n",
      "Iteration 353, loss = 0.40901018\n",
      "Iteration 354, loss = 0.40996861\n",
      "Iteration 355, loss = 0.40941587\n",
      "Iteration 356, loss = 0.40901677\n",
      "Iteration 357, loss = 0.40861143\n",
      "Iteration 358, loss = 0.40812281\n",
      "Iteration 359, loss = 0.40834670\n",
      "Iteration 360, loss = 0.40795043\n",
      "Iteration 361, loss = 0.40767515\n",
      "Iteration 362, loss = 0.40813355\n",
      "Iteration 363, loss = 0.40758412\n",
      "Iteration 364, loss = 0.40825921\n",
      "Iteration 365, loss = 0.40740460\n",
      "Iteration 366, loss = 0.40722727\n",
      "Iteration 367, loss = 0.40812659\n",
      "Iteration 368, loss = 0.40748328\n",
      "Iteration 369, loss = 0.40753971\n",
      "Iteration 370, loss = 0.40650064\n",
      "Iteration 371, loss = 0.40643970\n",
      "Iteration 372, loss = 0.40633149\n",
      "Iteration 373, loss = 0.40604386\n",
      "Iteration 374, loss = 0.40593050\n",
      "Iteration 375, loss = 0.40605617\n",
      "Iteration 376, loss = 0.40559947\n",
      "Iteration 377, loss = 0.40602075\n",
      "Iteration 378, loss = 0.40546499\n",
      "Iteration 379, loss = 0.40515706\n",
      "Iteration 380, loss = 0.40524963\n",
      "Iteration 381, loss = 0.40561034\n",
      "Iteration 382, loss = 0.40466044\n",
      "Iteration 383, loss = 0.40500854\n",
      "Iteration 384, loss = 0.40447689\n",
      "Iteration 385, loss = 0.40536362\n",
      "Iteration 386, loss = 0.40418841\n",
      "Iteration 387, loss = 0.40394345\n",
      "Iteration 388, loss = 0.40414067\n",
      "Iteration 389, loss = 0.40390871\n",
      "Iteration 390, loss = 0.40414760\n",
      "Iteration 391, loss = 0.40363565\n",
      "Iteration 392, loss = 0.40371462\n",
      "Iteration 393, loss = 0.40387720\n",
      "Iteration 394, loss = 0.40377418\n",
      "Iteration 395, loss = 0.40300494\n",
      "Iteration 396, loss = 0.40268639\n",
      "Iteration 397, loss = 0.40236421\n",
      "Iteration 398, loss = 0.40294041\n",
      "Iteration 399, loss = 0.40295726\n",
      "Iteration 400, loss = 0.40295089\n",
      "Iteration 401, loss = 0.40308798\n",
      "Iteration 402, loss = 0.40234939\n",
      "Iteration 403, loss = 0.40188482\n",
      "Iteration 404, loss = 0.40290539\n",
      "Iteration 405, loss = 0.40238985\n",
      "Iteration 406, loss = 0.40189017\n",
      "Iteration 407, loss = 0.40163383\n",
      "Iteration 408, loss = 0.40097734\n",
      "Iteration 409, loss = 0.40137887\n",
      "Iteration 410, loss = 0.40065829\n",
      "Iteration 411, loss = 0.40006994\n",
      "Iteration 412, loss = 0.40080765\n",
      "Iteration 413, loss = 0.40050969\n",
      "Iteration 414, loss = 0.40068218\n",
      "Iteration 415, loss = 0.40032209\n",
      "Iteration 416, loss = 0.39972284\n",
      "Iteration 417, loss = 0.40051100\n",
      "Iteration 418, loss = 0.39972681\n",
      "Iteration 419, loss = 0.39921832\n",
      "Iteration 420, loss = 0.39912349\n",
      "Iteration 421, loss = 0.39938417\n",
      "Iteration 422, loss = 0.39903807\n",
      "Iteration 423, loss = 0.39921012\n",
      "Iteration 424, loss = 0.40020112\n",
      "Iteration 425, loss = 0.39858012\n",
      "Iteration 426, loss = 0.39890358\n",
      "Iteration 427, loss = 0.39850462\n",
      "Iteration 428, loss = 0.39822579\n",
      "Iteration 429, loss = 0.39774333\n",
      "Iteration 430, loss = 0.39758890\n",
      "Iteration 431, loss = 0.39883017\n",
      "Iteration 432, loss = 0.39804667\n",
      "Iteration 433, loss = 0.39725418\n",
      "Iteration 434, loss = 0.39753815\n",
      "Iteration 435, loss = 0.39704344\n",
      "Iteration 436, loss = 0.39700082\n",
      "Iteration 437, loss = 0.39731807\n",
      "Iteration 438, loss = 0.39682528\n",
      "Iteration 439, loss = 0.39648703\n",
      "Iteration 440, loss = 0.39646797\n",
      "Iteration 441, loss = 0.39659194\n",
      "Iteration 442, loss = 0.39673053\n",
      "Iteration 443, loss = 0.39548287\n",
      "Iteration 444, loss = 0.39645932\n",
      "Iteration 445, loss = 0.39600781\n",
      "Iteration 446, loss = 0.39520612\n",
      "Iteration 447, loss = 0.39502734\n",
      "Iteration 448, loss = 0.39554196\n",
      "Iteration 449, loss = 0.39551760\n",
      "Iteration 450, loss = 0.39483553\n",
      "Iteration 451, loss = 0.39512535\n",
      "Iteration 452, loss = 0.39446351\n",
      "Iteration 453, loss = 0.39402335\n",
      "Iteration 454, loss = 0.39432030\n",
      "Iteration 455, loss = 0.39397719\n",
      "Iteration 456, loss = 0.39406278\n",
      "Iteration 457, loss = 0.39331552\n",
      "Iteration 458, loss = 0.39381257\n",
      "Iteration 459, loss = 0.39379513\n",
      "Iteration 460, loss = 0.39434226\n",
      "Iteration 461, loss = 0.39353827\n",
      "Iteration 462, loss = 0.39304833\n",
      "Iteration 463, loss = 0.39409005\n",
      "Iteration 464, loss = 0.39433372\n",
      "Iteration 465, loss = 0.39257406\n",
      "Iteration 466, loss = 0.39330606\n",
      "Iteration 467, loss = 0.39316011\n",
      "Iteration 468, loss = 0.39376973\n",
      "Iteration 469, loss = 0.39249191\n",
      "Iteration 470, loss = 0.39233141\n",
      "Iteration 471, loss = 0.39212630\n",
      "Iteration 472, loss = 0.39128901\n",
      "Iteration 473, loss = 0.39205503\n",
      "Iteration 474, loss = 0.39095931\n",
      "Iteration 475, loss = 0.39140255\n",
      "Iteration 476, loss = 0.39146915\n",
      "Iteration 477, loss = 0.39048841\n",
      "Iteration 478, loss = 0.39113350\n",
      "Iteration 479, loss = 0.39137422\n",
      "Iteration 480, loss = 0.38997478\n",
      "Iteration 481, loss = 0.39133624\n",
      "Iteration 482, loss = 0.39001534\n",
      "Iteration 483, loss = 0.38977015\n",
      "Iteration 484, loss = 0.39016962\n",
      "Iteration 485, loss = 0.38924305\n",
      "Iteration 486, loss = 0.38957816\n",
      "Iteration 487, loss = 0.38895538\n",
      "Iteration 488, loss = 0.38904025\n",
      "Iteration 489, loss = 0.38862497\n",
      "Iteration 490, loss = 0.38856807\n",
      "Iteration 491, loss = 0.38842844\n",
      "Iteration 492, loss = 0.38855844\n",
      "Iteration 493, loss = 0.38872874\n",
      "Iteration 494, loss = 0.38845681\n",
      "Iteration 495, loss = 0.38891396\n",
      "Iteration 496, loss = 0.38764805\n",
      "Iteration 497, loss = 0.38780049\n",
      "Iteration 498, loss = 0.38693433\n",
      "Iteration 499, loss = 0.38738027\n",
      "Iteration 500, loss = 0.38663734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7763561924257932"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 468,  283],\n",
       "       [ 154, 1049]], dtype=int64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2027it [00:00, 19657.97it/s]\u001b[A\n",
      "3271it [00:00, 16138.49it/s]\u001b[A\n",
      "4455it [00:00, 14404.20it/s]\u001b[A\n",
      "5733it [00:00, 13278.81it/s]\u001b[A\n",
      "6921it [00:00, 12733.84it/s]\u001b[A\n",
      "8071it [00:00, 12323.26it/s]\u001b[A\n",
      "9196it [00:00, 11968.69it/s]\u001b[A\n",
      "10387it [00:00, 11862.83it/s]\u001b[A\n",
      "11551it [00:00, 11793.36it/s]\u001b[A\n",
      "12891it [00:01, 11732.68it/s]\u001b[A\n",
      "14387it [00:01, 12543.21it/s]\u001b[A\n",
      "15660it [00:01, 12587.85it/s]\u001b[A\n",
      "16968it [00:01, 12228.62it/s]\u001b[A\n",
      "18187it [00:01, 12146.76it/s]\u001b[A\n",
      "19399it [00:01, 12018.89it/s]\u001b[A\n",
      "20600it [00:01, 11828.63it/s]\u001b[A\n",
      "21783it [00:01, 11538.04it/s]\u001b[A\n",
      "23235it [00:01, 11891.63it/s]\u001b[A\n",
      "24428it [00:01, 11899.84it/s]\u001b[A\n",
      "25621it [00:02, 11731.22it/s]\u001b[A\n",
      "26913it [00:02, 11879.51it/s]\u001b[A\n",
      "28124it [00:02, 11821.35it/s]\u001b[A\n",
      "29308it [00:02, 11738.18it/s]\u001b[A\n",
      "30483it [00:02, 11697.92it/s]\u001b[A\n",
      "31654it [00:02, 11642.97it/s]\u001b[A\n",
      "33042it [00:02, 11768.22it/s]\u001b[A\n",
      "34220it [00:02, 11765.80it/s]\u001b[A\n",
      "35426it [00:02, 11615.19it/s]\u001b[A\n",
      "36589it [00:03, 11619.27it/s]\u001b[A\n",
      "37773it [00:03, 11675.42it/s]\u001b[A\n",
      "38985it [00:03, 11804.20it/s]\u001b[A\n",
      "40167it [00:03, 11806.04it/s]\u001b[A\n",
      "41873it [00:03, 12957.67it/s]\u001b[A\n",
      "43204it [00:03, 12572.02it/s]\u001b[A\n",
      "44511it [00:03, 12495.83it/s]\u001b[A\n",
      "45780it [00:03, 12364.88it/s]\u001b[A\n",
      "47030it [00:03, 12378.60it/s]\u001b[A\n",
      "48302it [00:03, 11907.48it/s]\u001b[A\n",
      "49504it [00:04, 11843.50it/s]\u001b[A\n",
      "50696it [00:04, 11742.30it/s]\u001b[A\n",
      "52054it [00:04, 11954.27it/s]\u001b[A\n",
      "53255it [00:04, 11952.99it/s]\u001b[A\n",
      "54454it [00:04, 11781.76it/s]\u001b[A\n",
      "55637it [00:04, 11724.94it/s]\u001b[A\n",
      "56812it [00:04, 11665.52it/s]\u001b[A\n",
      "57993it [00:04, 11606.09it/s]\u001b[A\n",
      "59195it [00:04, 11563.61it/s]\u001b[A\n",
      "60406it [00:05, 11691.91it/s]\u001b[A\n",
      "61577it [00:05, 11673.30it/s]\u001b[A\n",
      "62745it [00:05, 11652.20it/s]\u001b[A\n",
      "64058it [00:05, 11568.96it/s]\u001b[A\n",
      "65217it [00:05, 11569.90it/s]\u001b[A\n",
      "66377it [00:05, 11548.08it/s]\u001b[A\n",
      "67570it [00:05, 11645.25it/s]\u001b[A\n",
      "68770it [00:05, 11635.01it/s]\u001b[A\n",
      "70056it [00:05, 11612.34it/s]\u001b[A\n",
      "71252it [00:05, 11592.67it/s]\u001b[A\n",
      "72413it [00:06, 11588.97it/s]\u001b[A\n",
      "73617it [00:06, 11586.16it/s]\u001b[A\n",
      "74827it [00:06, 11297.50it/s]\u001b[A\n",
      "76675it [00:06, 12414.14it/s]\u001b[A\n",
      "77952it [00:06, 12505.73it/s]\u001b[A\n",
      "79227it [00:06, 12012.18it/s]\u001b[A\n",
      "80450it [00:06, 12041.89it/s]\u001b[A\n",
      "81670it [00:06, 11568.52it/s]\u001b[A\n",
      "82842it [00:06, 11571.70it/s]\u001b[A\n",
      "84010it [00:07, 11525.61it/s]\u001b[A\n",
      "85304it [00:07, 11449.72it/s]\u001b[A\n",
      "86568it [00:07, 11478.14it/s]\u001b[A\n",
      "87721it [00:07, 11355.42it/s]\u001b[A\n",
      "88866it [00:07, 11357.37it/s]\u001b[A\n",
      "90133it [00:07, 11680.54it/s]\u001b[A\n",
      "91341it [00:07, 11773.35it/s]\u001b[A\n",
      "92522it [00:07, 11774.42it/s]\u001b[A\n",
      "93702it [00:07, 11665.02it/s]\u001b[A\n",
      "94871it [00:07, 11662.29it/s]\u001b[A\n",
      "96039it [00:08, 11665.36it/s]\u001b[A\n",
      "97207it [00:08, 11658.41it/s]\u001b[A\n",
      "98374it [00:08, 11651.65it/s]\u001b[A\n",
      "99540it [00:08, 11652.51it/s]\u001b[A\n",
      "100706it [00:08, 11643.84it/s]\u001b[A\n",
      "101871it [00:08, 11635.60it/s]\u001b[A\n",
      "103035it [00:08, 11630.40it/s]\u001b[A\n",
      "104199it [00:08, 11624.32it/s]\u001b[A\n",
      "105362it [00:08, 11306.89it/s]\u001b[A\n",
      "106609it [00:08, 11340.90it/s]\u001b[A\n",
      "107764it [00:09, 11400.86it/s]\u001b[A\n",
      "108928it [00:09, 11409.90it/s]\u001b[A\n",
      "110099it [00:09, 11355.99it/s]\u001b[A\n",
      "111299it [00:09, 11406.10it/s]\u001b[A\n",
      "112489it [00:09, 11432.34it/s]\u001b[A\n",
      "113637it [00:09, 11428.35it/s]\u001b[A\n",
      "114871it [00:09, 11276.77it/s]\u001b[A\n",
      "116244it [00:09, 11461.40it/s]\u001b[A\n",
      "117400it [00:09, 11460.09it/s]\u001b[A\n",
      "118710it [00:10, 11448.91it/s]\u001b[A\n",
      "119865it [00:10, 11446.19it/s]\u001b[A\n",
      "121012it [00:10, 11442.39it/s]\u001b[A\n",
      "122370it [00:10, 11541.22it/s]\u001b[A\n",
      "123547it [00:10, 11529.74it/s]\u001b[A\n",
      "124702it [00:10, 11534.99it/s]\u001b[A\n",
      "125856it [00:10, 11534.08it/s]\u001b[A\n",
      "127155it [00:10, 11466.31it/s]\u001b[A\n",
      "128302it [00:10, 11458.75it/s]\u001b[A\n",
      "129486it [00:10, 11566.10it/s]\u001b[A\n",
      "130643it [00:11, 11556.88it/s]\u001b[A\n",
      "131799it [00:11, 11549.91it/s]\u001b[A\n",
      "133077it [00:11, 11888.67it/s]\u001b[A\n",
      "134269it [00:11, 11859.22it/s]\u001b[A\n",
      "135457it [00:11, 11746.18it/s]\u001b[A\n",
      "136647it [00:11, 11737.76it/s]\u001b[A\n",
      "137962it [00:11, 11811.90it/s]\u001b[A\n",
      "139145it [00:11, 11714.16it/s]\u001b[A\n",
      "140462it [00:11, 11640.97it/s]\u001b[A\n",
      "141777it [00:12, 11584.61it/s]\u001b[A\n",
      "142936it [00:12, 11558.92it/s]\u001b[A\n",
      "144093it [00:12, 11511.11it/s]\u001b[A\n",
      "145245it [00:12, 11483.85it/s]\u001b[A\n",
      "146560it [00:12, 11479.51it/s]\u001b[A\n",
      "147792it [00:12, 11581.20it/s]\u001b[A\n",
      "149099it [00:12, 11513.79it/s]\u001b[A\n",
      "150422it [00:12, 11531.02it/s]\u001b[A\n",
      "151591it [00:12, 11539.96it/s]\u001b[A\n",
      "152752it [00:12, 11529.07it/s]\u001b[A\n",
      "153906it [00:13, 11528.46it/s]\u001b[A\n",
      "155059it [00:13, 11528.08it/s]\u001b[A\n",
      "156213it [00:13, 11498.97it/s]\u001b[A\n",
      "157363it [00:13, 11487.76it/s]\u001b[A\n",
      "158512it [00:13, 11450.06it/s]\u001b[A\n",
      "159658it [00:13, 11419.47it/s]\u001b[A\n",
      "160809it [00:13, 11436.08it/s]\u001b[A\n",
      "161999it [00:13, 11458.87it/s]\u001b[A\n",
      "163209it [00:13, 11511.63it/s]\u001b[A\n",
      "164421it [00:13, 11653.65it/s]\u001b[A\n",
      "165587it [00:14, 11524.26it/s]\u001b[A\n",
      "166746it [00:14, 11516.77it/s]\u001b[A\n",
      "167930it [00:14, 11561.12it/s]\u001b[A\n",
      "169087it [00:14, 11497.24it/s]\u001b[A\n",
      "170424it [00:14, 11998.59it/s]\u001b[A\n",
      "171630it [00:14, 11873.06it/s]\u001b[A\n",
      "172822it [00:14, 11884.21it/s]\u001b[A\n",
      "174014it [00:14, 11894.14it/s]\u001b[A\n",
      "175206it [00:14, 11101.71it/s]\u001b[A\n",
      "176329it [00:15, 11096.18it/s]\u001b[A\n",
      "177448it [00:15, 10835.23it/s]\u001b[A\n",
      "178755it [00:15, 11230.00it/s]\u001b[A\n",
      "180285it [00:15, 11773.36it/s]\u001b[A\n",
      "181476it [00:15, 11677.24it/s]\u001b[A\n",
      "182752it [00:15, 11481.05it/s]\u001b[A\n",
      "183913it [00:15, 11505.50it/s]\u001b[A\n",
      "185096it [00:15, 11573.61it/s]\u001b[A\n",
      "186282it [00:15, 11652.68it/s]\u001b[A\n",
      "187617it [00:15, 11629.79it/s]\u001b[A\n",
      "188782it [00:16, 11561.62it/s]\u001b[A\n",
      "189940it [00:16, 11500.78it/s]\u001b[A\n",
      "191241it [00:16, 11495.16it/s]\u001b[A\n",
      "192392it [00:16, 11485.05it/s]\u001b[A\n",
      "193542it [00:16, 11405.06it/s]\u001b[A\n",
      "194815it [00:16, 11332.02it/s]\u001b[A\n",
      "196019it [00:16, 11377.98it/s]\u001b[A\n",
      "197288it [00:16, 11381.46it/s]\u001b[A\n",
      "198591it [00:16, 11828.77it/s]\u001b[A\n",
      "199779it [00:17, 11732.28it/s]\u001b[A\n",
      "200958it [00:17, 11729.32it/s]\u001b[A\n",
      "202333it [00:17, 12116.73it/s]\u001b[A\n",
      "203560it [00:17, 11957.67it/s]\u001b[A\n",
      "204760it [00:17, 11888.27it/s]\u001b[A\n",
      "205952it [00:17, 11354.14it/s]\u001b[A\n",
      "207138it [00:17, 11475.04it/s]\u001b[A\n",
      "208291it [00:17, 11454.50it/s]\u001b[A\n",
      "209441it [00:17, 11403.09it/s]\u001b[A\n",
      "210889it [00:17, 12000.19it/s]\u001b[A\n",
      "212100it [00:18, 11787.89it/s]\u001b[A\n",
      "213316it [00:18, 11891.62it/s]\u001b[A\n",
      "214511it [00:18, 11864.92it/s]\u001b[A\n",
      "215837it [00:18, 12231.89it/s]\u001b[A\n",
      "217066it [00:18, 12112.46it/s]\u001b[A\n",
      "218282it [00:18, 11857.16it/s]\u001b[A\n",
      "219544it [00:18, 11687.46it/s]\u001b[A\n",
      "220817it [00:18, 11654.19it/s]\u001b[A\n",
      "222189it [00:18, 11734.87it/s]\u001b[A\n",
      "223365it [00:19, 11700.26it/s]\u001b[A\n",
      "224537it [00:19, 11629.41it/s]\u001b[A\n",
      "225709it [00:19, 11630.55it/s]\u001b[A\n",
      "227005it [00:19, 11592.78it/s]\u001b[A\n",
      "228165it [00:19, 11519.34it/s]\u001b[A\n",
      "229318it [00:19, 11445.96it/s]\u001b[A\n",
      "230637it [00:19, 11485.28it/s]\u001b[A\n",
      "231800it [00:19, 11460.17it/s]\u001b[A\n",
      "232947it [00:19, 11377.31it/s]\u001b[A\n",
      "234228it [00:19, 11410.76it/s]\u001b[A\n",
      "235370it [00:20, 11367.55it/s]\u001b[A\n",
      "236516it [00:20, 11311.86it/s]\u001b[A\n",
      "238025it [00:20, 11860.55it/s]\u001b[A\n",
      "239219it [00:20, 11835.44it/s]\u001b[A\n",
      "240408it [00:20, 11789.43it/s]\u001b[A\n",
      "241591it [00:20, 11453.03it/s]\u001b[A\n",
      "242741it [00:20, 11464.37it/s]\u001b[A\n",
      "244042it [00:20, 11865.07it/s]\u001b[A\n",
      "245498it [00:20, 12511.15it/s]\u001b[A\n",
      "246763it [00:21, 12455.94it/s]\u001b[A\n",
      "248019it [00:21, 12036.19it/s]\u001b[A\n",
      "249288it [00:21, 12184.00it/s]\u001b[A\n",
      "250514it [00:21, 12104.98it/s]\u001b[A\n",
      "251730it [00:21, 11827.94it/s]\u001b[A\n",
      "252918it [00:21, 11778.56it/s]\u001b[A\n",
      "254100it [00:21, 11478.87it/s]\u001b[A\n",
      "255253it [00:21, 11406.52it/s]\u001b[A\n",
      "256653it [00:21, 12048.86it/s]\u001b[A\n",
      "257870it [00:21, 12066.63it/s]\u001b[A\n",
      "259292it [00:22, 12615.52it/s]\u001b[A\n",
      "260566it [00:22, 12277.27it/s]\u001b[A\n",
      "261805it [00:22, 12126.18it/s]\u001b[A\n",
      "263026it [00:22, 11855.19it/s]\u001b[A\n",
      "264219it [00:22, 11813.23it/s]\u001b[A\n",
      "265406it [00:22, 11678.40it/s]\u001b[A\n",
      "266578it [00:22, 11362.27it/s]\u001b[A\n",
      "268104it [00:22, 12296.26it/s]\u001b[A\n",
      "269359it [00:22, 12023.83it/s]\u001b[A\n",
      "270581it [00:23, 11915.34it/s]\u001b[A\n",
      "271787it [00:23, 11830.15it/s]\u001b[A\n",
      "272980it [00:23, 11721.83it/s]\u001b[A\n",
      "274288it [00:23, 11985.63it/s]\u001b[A\n",
      "275507it [00:23, 12044.40it/s]\u001b[A\n",
      "276734it [00:23, 11985.17it/s]\u001b[A\n",
      "277936it [00:23, 11939.47it/s]\u001b[A\n",
      "279133it [00:23, 11678.60it/s]\u001b[A\n",
      "280382it [00:23, 11895.70it/s]\u001b[A\n",
      "281990it [00:23, 12870.12it/s]\u001b[A\n",
      "283303it [00:24, 12908.74it/s]\u001b[A\n",
      "285109it [00:24, 14099.87it/s]\u001b[A\n",
      "286660it [00:24, 14053.72it/s]\u001b[A\n",
      "288097it [00:24, 13329.83it/s]\u001b[A\n",
      "289460it [00:24, 12786.12it/s]\u001b[A\n",
      "290765it [00:24, 12224.50it/s]\u001b[A\n",
      "292180it [00:24, 12711.44it/s]\u001b[A\n",
      "294146it [00:24, 13866.09it/s]\u001b[A\n",
      "295579it [00:24, 13268.91it/s]\u001b[A\n",
      "296944it [00:25, 12722.24it/s]\u001b[A\n",
      "298248it [00:25, 12251.08it/s]\u001b[A\n",
      "299499it [00:25, 12008.24it/s]\u001b[A\n",
      "300789it [00:25, 12233.12it/s]\u001b[A\n",
      "302027it [00:25, 12029.07it/s]\u001b[A\n",
      "303241it [00:25, 11938.63it/s]\u001b[A\n",
      "304540it [00:25, 11887.29it/s]\u001b[A\n",
      "305735it [00:25, 11871.84it/s]\u001b[A\n",
      "306926it [00:25, 11788.83it/s]\u001b[A\n",
      "308108it [00:26, 11703.83it/s]\u001b[A\n",
      "309421it [00:26, 12070.63it/s]\u001b[A\n",
      "310782it [00:26, 12471.32it/s]\u001b[A\n",
      "312036it [00:26, 12432.80it/s]\u001b[A\n",
      "313284it [00:26, 12200.08it/s]\u001b[A\n",
      "314509it [00:26, 12008.43it/s]\u001b[A\n",
      "315757it [00:26, 12015.60it/s]\u001b[A\n",
      "317074it [00:26, 12044.57it/s]\u001b[A\n",
      "318281it [00:26, 11909.41it/s]\u001b[A\n",
      "319505it [00:26, 11546.78it/s]\u001b[A\n",
      "320664it [00:27, 11381.21it/s]\u001b[A\n",
      "321897it [00:27, 11320.16it/s]\u001b[A\n",
      "323094it [00:27, 11506.64it/s]\u001b[A\n",
      "324247it [00:27, 11456.36it/s]\u001b[A\n",
      "325395it [00:27, 11457.64it/s]\u001b[A\n",
      "326577it [00:27, 11472.56it/s]\u001b[A\n",
      "327917it [00:27, 11577.66it/s]\u001b[A\n",
      "329084it [00:27, 11525.46it/s]\u001b[A\n",
      "330238it [00:27, 11486.87it/s]\u001b[A\n",
      "331388it [00:27, 11487.50it/s]\u001b[A\n",
      "332538it [00:28, 11458.05it/s]\u001b[A\n",
      "333796it [00:28, 11339.67it/s]\u001b[A\n",
      "334935it [00:28, 11320.11it/s]\u001b[A\n",
      "336259it [00:28, 11361.34it/s]\u001b[A\n",
      "337409it [00:28, 11387.30it/s]\u001b[A\n",
      "338551it [00:28, 11382.45it/s]\u001b[A\n",
      "339692it [00:28, 11382.27it/s]\u001b[A\n",
      "340831it [00:28, 11304.40it/s]\u001b[A\n",
      "342059it [00:28, 11209.51it/s]\u001b[A\n",
      "343218it [00:29, 11236.13it/s]\u001b[A\n",
      "344498it [00:29, 11250.23it/s]\u001b[A\n",
      "345793it [00:29, 11255.63it/s]\u001b[A\n",
      "346936it [00:29, 11246.40it/s]\u001b[A\n",
      "348089it [00:29, 11208.30it/s]\u001b[A\n",
      "349268it [00:29, 11249.04it/s]\u001b[A\n",
      "350394it [00:29, 10229.49it/s]\u001b[A\n",
      "351520it [00:29, 10499.65it/s]\u001b[A\n",
      "352709it [00:29, 10787.69it/s]\u001b[A\n",
      "353874it [00:30, 10980.07it/s]\u001b[A\n",
      "355036it [00:30, 11135.15it/s]\u001b[A\n",
      "356188it [00:30, 11215.42it/s]\u001b[A\n",
      "357495it [00:30, 11687.16it/s]\u001b[A\n",
      "359058it [00:30, 12589.42it/s]\u001b[A\n",
      "360343it [00:30, 12452.37it/s]\u001b[A\n",
      "361607it [00:30, 12057.10it/s]\u001b[A\n",
      "362829it [00:30, 12096.53it/s]\u001b[A\n",
      "364050it [00:30, 11591.41it/s]\u001b[A\n",
      "365222it [00:30, 11564.70it/s]\u001b[A\n",
      "366388it [00:31, 11432.45it/s]\u001b[A\n",
      "367615it [00:31, 11377.73it/s]\u001b[A\n",
      "368760it [00:31, 11357.73it/s]\u001b[A\n",
      "370017it [00:31, 11310.02it/s]\u001b[A\n",
      "371270it [00:31, 11607.40it/s]\u001b[A\n",
      "372650it [00:31, 12167.55it/s]\u001b[A\n",
      "373981it [00:31, 12477.91it/s]\u001b[A\n",
      "375238it [00:31, 12136.30it/s]\u001b[A\n",
      "376460it [00:31, 11511.22it/s]\u001b[A\n",
      "377624it [00:32, 11447.76it/s]\u001b[A\n",
      "378778it [00:32, 11188.94it/s]\u001b[A\n",
      "379905it [00:32, 11106.75it/s]\u001b[A\n",
      "381036it [00:32, 11147.54it/s]\u001b[A\n",
      "382239it [00:32, 11158.66it/s]\u001b[A\n",
      "383358it [00:32, 11037.91it/s]\u001b[A\n",
      "384464it [00:32, 11002.90it/s]\u001b[A\n",
      "385850it [00:32, 11719.86it/s]\u001b[A\n",
      "387157it [00:32, 12073.42it/s]\u001b[A\n",
      "388377it [00:32, 11785.06it/s]\u001b[A\n",
      "389566it [00:33, 11639.34it/s]\u001b[A\n",
      "390738it [00:33, 11479.00it/s]\u001b[A\n",
      "391902it [00:33, 11367.84it/s]\u001b[A\n",
      "393044it [00:33, 11380.02it/s]\u001b[A\n",
      "394186it [00:33, 11178.56it/s]\u001b[A\n",
      "395307it [00:33, 11032.78it/s]\u001b[A\n",
      "396437it [00:33, 10956.80it/s]\u001b[A\n",
      "397567it [00:33, 11033.83it/s]\u001b[A\n",
      "398695it [00:33, 11017.70it/s]\u001b[A\n",
      "400000it [00:34, 11761.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "embeddings_index = {}\n",
    "f = open('GLOVE_models/glove.6B.100d.txt',encoding=\"utf8\")\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(100)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_glove = [sent2vec(x) for x in df_bin['content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7814\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(features_glove))\n",
    "for x in features_glove:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_glove = np.array(features_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n",
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n",
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n",
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n",
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.746095</td>\n",
       "      <td>0.043386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.044635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.677116</td>\n",
       "      <td>0.030035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Accuracy  Standard deviation\n",
       "model_name                                               \n",
       "LinearSVC                    0.746095            0.043386\n",
       "LogisticRegression           0.746606            0.044635\n",
       "MultinomialNB                     NaN                 NaN\n",
       "RandomForestClassifier       0.677116            0.030035"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accu = model_testing(features_glove, labels)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        0\n",
       "2        0\n",
       "6        0\n",
       "8        0\n",
       "9        0\n",
       "        ..\n",
       "29991    1\n",
       "29995    1\n",
       "29996    0\n",
       "29997    1\n",
       "29999    1\n",
       "Name: sentiment, Length: 7814, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_glove, labels, test_size=0.33, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.56%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.46%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(300,100,200), max_iter=500, alpha=0.0001,learning_rate = 'constant',\n",
    "                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68052900\n",
      "Iteration 2, loss = 0.67444414\n",
      "Iteration 3, loss = 0.67037641\n",
      "Iteration 4, loss = 0.66818580\n",
      "Iteration 5, loss = 0.66679737\n",
      "Iteration 6, loss = 0.66609670\n",
      "Iteration 7, loss = 0.66563735\n",
      "Iteration 8, loss = 0.66528829\n",
      "Iteration 9, loss = 0.66496139\n",
      "Iteration 10, loss = 0.66470802\n",
      "Iteration 11, loss = 0.66448951\n",
      "Iteration 12, loss = 0.66424379\n",
      "Iteration 13, loss = 0.66402956\n",
      "Iteration 14, loss = 0.66381197\n",
      "Iteration 15, loss = 0.66361644\n",
      "Iteration 16, loss = 0.66341214\n",
      "Iteration 17, loss = 0.66321462\n",
      "Iteration 18, loss = 0.66303650\n",
      "Iteration 19, loss = 0.66282612\n",
      "Iteration 20, loss = 0.66260810\n",
      "Iteration 21, loss = 0.66241448\n",
      "Iteration 22, loss = 0.66225008\n",
      "Iteration 23, loss = 0.66202129\n",
      "Iteration 24, loss = 0.66180715\n",
      "Iteration 25, loss = 0.66161275\n",
      "Iteration 26, loss = 0.66137937\n",
      "Iteration 27, loss = 0.66117423\n",
      "Iteration 28, loss = 0.66099427\n",
      "Iteration 29, loss = 0.66074626\n",
      "Iteration 30, loss = 0.66050205\n",
      "Iteration 31, loss = 0.66027423\n",
      "Iteration 32, loss = 0.66004950\n",
      "Iteration 33, loss = 0.65982698\n",
      "Iteration 34, loss = 0.65956841\n",
      "Iteration 35, loss = 0.65930387\n",
      "Iteration 36, loss = 0.65904927\n",
      "Iteration 37, loss = 0.65878535\n",
      "Iteration 38, loss = 0.65852792\n",
      "Iteration 39, loss = 0.65824650\n",
      "Iteration 40, loss = 0.65795856\n",
      "Iteration 41, loss = 0.65767842\n",
      "Iteration 42, loss = 0.65741341\n",
      "Iteration 43, loss = 0.65710975\n",
      "Iteration 44, loss = 0.65680682\n",
      "Iteration 45, loss = 0.65650762\n",
      "Iteration 46, loss = 0.65622058\n",
      "Iteration 47, loss = 0.65587312\n",
      "Iteration 48, loss = 0.65554567\n",
      "Iteration 49, loss = 0.65520639\n",
      "Iteration 50, loss = 0.65487845\n",
      "Iteration 51, loss = 0.65453459\n",
      "Iteration 52, loss = 0.65414966\n",
      "Iteration 53, loss = 0.65379760\n",
      "Iteration 54, loss = 0.65340561\n",
      "Iteration 55, loss = 0.65302360\n",
      "Iteration 56, loss = 0.65264084\n",
      "Iteration 57, loss = 0.65220172\n",
      "Iteration 58, loss = 0.65175619\n",
      "Iteration 59, loss = 0.65134552\n",
      "Iteration 60, loss = 0.65084520\n",
      "Iteration 61, loss = 0.65035082\n",
      "Iteration 62, loss = 0.64985664\n",
      "Iteration 63, loss = 0.64935085\n",
      "Iteration 64, loss = 0.64885529\n",
      "Iteration 65, loss = 0.64833148\n",
      "Iteration 66, loss = 0.64779883\n",
      "Iteration 67, loss = 0.64722885\n",
      "Iteration 68, loss = 0.64663653\n",
      "Iteration 69, loss = 0.64608285\n",
      "Iteration 70, loss = 0.64547087\n",
      "Iteration 71, loss = 0.64485577\n",
      "Iteration 72, loss = 0.64424278\n",
      "Iteration 73, loss = 0.64359480\n",
      "Iteration 74, loss = 0.64295388\n",
      "Iteration 75, loss = 0.64227388\n",
      "Iteration 76, loss = 0.64161321\n",
      "Iteration 77, loss = 0.64090625\n",
      "Iteration 78, loss = 0.64016308\n",
      "Iteration 79, loss = 0.63943158\n",
      "Iteration 80, loss = 0.63866018\n",
      "Iteration 81, loss = 0.63782016\n",
      "Iteration 82, loss = 0.63700585\n",
      "Iteration 83, loss = 0.63616988\n",
      "Iteration 84, loss = 0.63525391\n",
      "Iteration 85, loss = 0.63439117\n",
      "Iteration 86, loss = 0.63347493\n",
      "Iteration 87, loss = 0.63255463\n",
      "Iteration 88, loss = 0.63163104\n",
      "Iteration 89, loss = 0.63060559\n",
      "Iteration 90, loss = 0.62960344\n",
      "Iteration 91, loss = 0.62859848\n",
      "Iteration 92, loss = 0.62758859\n",
      "Iteration 93, loss = 0.62655480\n",
      "Iteration 94, loss = 0.62534105\n",
      "Iteration 95, loss = 0.62422909\n",
      "Iteration 96, loss = 0.62309125\n",
      "Iteration 97, loss = 0.62195635\n",
      "Iteration 98, loss = 0.62063308\n",
      "Iteration 99, loss = 0.61940340\n",
      "Iteration 100, loss = 0.61813965\n",
      "Iteration 101, loss = 0.61685513\n",
      "Iteration 102, loss = 0.61554583\n",
      "Iteration 103, loss = 0.61416538\n",
      "Iteration 104, loss = 0.61279182\n",
      "Iteration 105, loss = 0.61143543\n",
      "Iteration 106, loss = 0.61000721\n",
      "Iteration 107, loss = 0.60862707\n",
      "Iteration 108, loss = 0.60710798\n",
      "Iteration 109, loss = 0.60560646\n",
      "Iteration 110, loss = 0.60401906\n",
      "Iteration 111, loss = 0.60246296\n",
      "Iteration 112, loss = 0.60090034\n",
      "Iteration 113, loss = 0.59959278\n",
      "Iteration 114, loss = 0.59777052\n",
      "Iteration 115, loss = 0.59614828\n",
      "Iteration 116, loss = 0.59456782\n",
      "Iteration 117, loss = 0.59300895\n",
      "Iteration 118, loss = 0.59125217\n",
      "Iteration 119, loss = 0.58965765\n",
      "Iteration 120, loss = 0.58808121\n",
      "Iteration 121, loss = 0.58634543\n",
      "Iteration 122, loss = 0.58470008\n",
      "Iteration 123, loss = 0.58317410\n",
      "Iteration 124, loss = 0.58138999\n",
      "Iteration 125, loss = 0.57983912\n",
      "Iteration 126, loss = 0.57811991\n",
      "Iteration 127, loss = 0.57646875\n",
      "Iteration 128, loss = 0.57486205\n",
      "Iteration 129, loss = 0.57327976\n",
      "Iteration 130, loss = 0.57159402\n",
      "Iteration 131, loss = 0.57000540\n",
      "Iteration 132, loss = 0.56857123\n",
      "Iteration 133, loss = 0.56688601\n",
      "Iteration 134, loss = 0.56536556\n",
      "Iteration 135, loss = 0.56385885\n",
      "Iteration 136, loss = 0.56237993\n",
      "Iteration 137, loss = 0.56103451\n",
      "Iteration 138, loss = 0.55963089\n",
      "Iteration 139, loss = 0.55814885\n",
      "Iteration 140, loss = 0.55670360\n",
      "Iteration 141, loss = 0.55534054\n",
      "Iteration 142, loss = 0.55407664\n",
      "Iteration 143, loss = 0.55272332\n",
      "Iteration 144, loss = 0.55143544\n",
      "Iteration 145, loss = 0.55017505\n",
      "Iteration 146, loss = 0.54897905\n",
      "Iteration 147, loss = 0.54776607\n",
      "Iteration 148, loss = 0.54673193\n",
      "Iteration 149, loss = 0.54584780\n",
      "Iteration 150, loss = 0.54427813\n",
      "Iteration 151, loss = 0.54335003\n",
      "Iteration 152, loss = 0.54245022\n",
      "Iteration 153, loss = 0.54127117\n",
      "Iteration 154, loss = 0.54027455\n",
      "Iteration 155, loss = 0.53924016\n",
      "Iteration 156, loss = 0.53836039\n",
      "Iteration 157, loss = 0.53731187\n",
      "Iteration 158, loss = 0.53641667\n",
      "Iteration 159, loss = 0.53555349\n",
      "Iteration 160, loss = 0.53495906\n",
      "Iteration 161, loss = 0.53391584\n",
      "Iteration 162, loss = 0.53297403\n",
      "Iteration 163, loss = 0.53233030\n",
      "Iteration 164, loss = 0.53158580\n",
      "Iteration 165, loss = 0.53074531\n",
      "Iteration 166, loss = 0.53037209\n",
      "Iteration 167, loss = 0.52908056\n",
      "Iteration 168, loss = 0.52930099\n",
      "Iteration 169, loss = 0.52774679\n",
      "Iteration 170, loss = 0.52721445\n",
      "Iteration 171, loss = 0.52635308\n",
      "Iteration 172, loss = 0.52574722\n",
      "Iteration 173, loss = 0.52529270\n",
      "Iteration 174, loss = 0.52486030\n",
      "Iteration 175, loss = 0.52417049\n",
      "Iteration 176, loss = 0.52369829\n",
      "Iteration 177, loss = 0.52336589\n",
      "Iteration 178, loss = 0.52219440\n",
      "Iteration 179, loss = 0.52175414\n",
      "Iteration 180, loss = 0.52124122\n",
      "Iteration 181, loss = 0.52073252\n",
      "Iteration 182, loss = 0.52021862\n",
      "Iteration 183, loss = 0.51990954\n",
      "Iteration 184, loss = 0.51931533\n",
      "Iteration 185, loss = 0.51861931\n",
      "Iteration 186, loss = 0.51840981\n",
      "Iteration 187, loss = 0.51768636\n",
      "Iteration 188, loss = 0.51772447\n",
      "Iteration 189, loss = 0.51687260\n",
      "Iteration 190, loss = 0.51661798\n",
      "Iteration 191, loss = 0.51611330\n",
      "Iteration 192, loss = 0.51583155\n",
      "Iteration 193, loss = 0.51548008\n",
      "Iteration 194, loss = 0.51500584\n",
      "Iteration 195, loss = 0.51439570\n",
      "Iteration 196, loss = 0.51411456\n",
      "Iteration 197, loss = 0.51400545\n",
      "Iteration 198, loss = 0.51348315\n",
      "Iteration 199, loss = 0.51321767\n",
      "Iteration 200, loss = 0.51264308\n",
      "Iteration 201, loss = 0.51240749\n",
      "Iteration 202, loss = 0.51234135\n",
      "Iteration 203, loss = 0.51171848\n",
      "Iteration 204, loss = 0.51138738\n",
      "Iteration 205, loss = 0.51110233\n",
      "Iteration 206, loss = 0.51114864\n",
      "Iteration 207, loss = 0.51047372\n",
      "Iteration 208, loss = 0.51018349\n",
      "Iteration 209, loss = 0.51009906\n",
      "Iteration 210, loss = 0.50956636\n",
      "Iteration 211, loss = 0.50946052\n",
      "Iteration 212, loss = 0.50910208\n",
      "Iteration 213, loss = 0.50867983\n",
      "Iteration 214, loss = 0.50828414\n",
      "Iteration 215, loss = 0.50922405\n",
      "Iteration 216, loss = 0.50798387\n",
      "Iteration 217, loss = 0.50759095\n",
      "Iteration 218, loss = 0.50827949\n",
      "Iteration 219, loss = 0.50718707\n",
      "Iteration 220, loss = 0.50666402\n",
      "Iteration 221, loss = 0.50670683\n",
      "Iteration 222, loss = 0.50708274\n",
      "Iteration 223, loss = 0.50609070\n",
      "Iteration 224, loss = 0.50576304\n",
      "Iteration 225, loss = 0.50573489\n",
      "Iteration 226, loss = 0.50555631\n",
      "Iteration 227, loss = 0.50524357\n",
      "Iteration 228, loss = 0.50532530\n",
      "Iteration 229, loss = 0.50466308\n",
      "Iteration 230, loss = 0.50453462\n",
      "Iteration 231, loss = 0.50432279\n",
      "Iteration 232, loss = 0.50403579\n",
      "Iteration 233, loss = 0.50416396\n",
      "Iteration 234, loss = 0.50377356\n",
      "Iteration 235, loss = 0.50379269\n",
      "Iteration 236, loss = 0.50347320\n",
      "Iteration 237, loss = 0.50350570\n",
      "Iteration 238, loss = 0.50360880\n",
      "Iteration 239, loss = 0.50268390\n",
      "Iteration 240, loss = 0.50248789\n",
      "Iteration 241, loss = 0.50248077\n",
      "Iteration 242, loss = 0.50256049\n",
      "Iteration 243, loss = 0.50217081\n",
      "Iteration 244, loss = 0.50186583\n",
      "Iteration 245, loss = 0.50183022\n",
      "Iteration 246, loss = 0.50174573\n",
      "Iteration 247, loss = 0.50120243\n",
      "Iteration 248, loss = 0.50114606\n",
      "Iteration 249, loss = 0.50154687\n",
      "Iteration 250, loss = 0.50143516\n",
      "Iteration 251, loss = 0.50067641\n",
      "Iteration 252, loss = 0.50069960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.50024103\n",
      "Iteration 254, loss = 0.50117516\n",
      "Iteration 255, loss = 0.49986405\n",
      "Iteration 256, loss = 0.49983523\n",
      "Iteration 257, loss = 0.50115589\n",
      "Iteration 258, loss = 0.49955437\n",
      "Iteration 259, loss = 0.50018036\n",
      "Iteration 260, loss = 0.49950839\n",
      "Iteration 261, loss = 0.49934823\n",
      "Iteration 262, loss = 0.49939912\n",
      "Iteration 263, loss = 0.49918846\n",
      "Iteration 264, loss = 0.49870605\n",
      "Iteration 265, loss = 0.49871026\n",
      "Iteration 266, loss = 0.49865209\n",
      "Iteration 267, loss = 0.49831916\n",
      "Iteration 268, loss = 0.49859013\n",
      "Iteration 269, loss = 0.49823991\n",
      "Iteration 270, loss = 0.49797093\n",
      "Iteration 271, loss = 0.49787253\n",
      "Iteration 272, loss = 0.49788942\n",
      "Iteration 273, loss = 0.49747365\n",
      "Iteration 274, loss = 0.49741986\n",
      "Iteration 275, loss = 0.49735042\n",
      "Iteration 276, loss = 0.49725880\n",
      "Iteration 277, loss = 0.49704788\n",
      "Iteration 278, loss = 0.49712546\n",
      "Iteration 279, loss = 0.49697682\n",
      "Iteration 280, loss = 0.49658240\n",
      "Iteration 281, loss = 0.49709412\n",
      "Iteration 282, loss = 0.49680434\n",
      "Iteration 283, loss = 0.49659230\n",
      "Iteration 284, loss = 0.49626153\n",
      "Iteration 285, loss = 0.49638882\n",
      "Iteration 286, loss = 0.49622842\n",
      "Iteration 287, loss = 0.49642430\n",
      "Iteration 288, loss = 0.49598889\n",
      "Iteration 289, loss = 0.49578017\n",
      "Iteration 290, loss = 0.49683814\n",
      "Iteration 291, loss = 0.49583738\n",
      "Iteration 292, loss = 0.49525895\n",
      "Iteration 293, loss = 0.49639580\n",
      "Iteration 294, loss = 0.49500960\n",
      "Iteration 295, loss = 0.49503779\n",
      "Iteration 296, loss = 0.49547659\n",
      "Iteration 297, loss = 0.49519008\n",
      "Iteration 298, loss = 0.49519273\n",
      "Iteration 299, loss = 0.49469862\n",
      "Iteration 300, loss = 0.49425743\n",
      "Iteration 301, loss = 0.49454487\n",
      "Iteration 302, loss = 0.49458703\n",
      "Iteration 303, loss = 0.49544737\n",
      "Iteration 304, loss = 0.49403388\n",
      "Iteration 305, loss = 0.49493738\n",
      "Iteration 306, loss = 0.49442282\n",
      "Iteration 307, loss = 0.49390333\n",
      "Iteration 308, loss = 0.49367940\n",
      "Iteration 309, loss = 0.49391966\n",
      "Iteration 310, loss = 0.49375349\n",
      "Iteration 311, loss = 0.49349712\n",
      "Iteration 312, loss = 0.49347142\n",
      "Iteration 313, loss = 0.49315008\n",
      "Iteration 314, loss = 0.49297960\n",
      "Iteration 315, loss = 0.49289526\n",
      "Iteration 316, loss = 0.49282360\n",
      "Iteration 317, loss = 0.49289164\n",
      "Iteration 318, loss = 0.49231933\n",
      "Iteration 319, loss = 0.49260099\n",
      "Iteration 320, loss = 0.49318281\n",
      "Iteration 321, loss = 0.49253583\n",
      "Iteration 322, loss = 0.49262801\n",
      "Iteration 323, loss = 0.49250535\n",
      "Iteration 324, loss = 0.49203612\n",
      "Iteration 325, loss = 0.49262328\n",
      "Iteration 326, loss = 0.49257009\n",
      "Iteration 327, loss = 0.49223549\n",
      "Iteration 328, loss = 0.49224247\n",
      "Iteration 329, loss = 0.49175279\n",
      "Iteration 330, loss = 0.49181746\n",
      "Iteration 331, loss = 0.49143928\n",
      "Iteration 332, loss = 0.49127852\n",
      "Iteration 333, loss = 0.49171168\n",
      "Iteration 334, loss = 0.49135117\n",
      "Iteration 335, loss = 0.49154896\n",
      "Iteration 336, loss = 0.49173146\n",
      "Iteration 337, loss = 0.49154037\n",
      "Iteration 338, loss = 0.49082087\n",
      "Iteration 339, loss = 0.49102459\n",
      "Iteration 340, loss = 0.49083530\n",
      "Iteration 341, loss = 0.49051077\n",
      "Iteration 342, loss = 0.49046868\n",
      "Iteration 343, loss = 0.49066036\n",
      "Iteration 344, loss = 0.49094878\n",
      "Iteration 345, loss = 0.49183860\n",
      "Iteration 346, loss = 0.49026082\n",
      "Iteration 347, loss = 0.49003687\n",
      "Iteration 348, loss = 0.48995274\n",
      "Iteration 349, loss = 0.49104161\n",
      "Iteration 350, loss = 0.48975501\n",
      "Iteration 351, loss = 0.48981467\n",
      "Iteration 352, loss = 0.48972968\n",
      "Iteration 353, loss = 0.48984906\n",
      "Iteration 354, loss = 0.48973452\n",
      "Iteration 355, loss = 0.49029183\n",
      "Iteration 356, loss = 0.48940388\n",
      "Iteration 357, loss = 0.48967207\n",
      "Iteration 358, loss = 0.48907973\n",
      "Iteration 359, loss = 0.48942064\n",
      "Iteration 360, loss = 0.48909757\n",
      "Iteration 361, loss = 0.48895860\n",
      "Iteration 362, loss = 0.48911366\n",
      "Iteration 363, loss = 0.48916656\n",
      "Iteration 364, loss = 0.48877615\n",
      "Iteration 365, loss = 0.48876257\n",
      "Iteration 366, loss = 0.48913890\n",
      "Iteration 367, loss = 0.48842152\n",
      "Iteration 368, loss = 0.48881444\n",
      "Iteration 369, loss = 0.48840875\n",
      "Iteration 370, loss = 0.48801296\n",
      "Iteration 371, loss = 0.48779891\n",
      "Iteration 372, loss = 0.48878664\n",
      "Iteration 373, loss = 0.48809768\n",
      "Iteration 374, loss = 0.48811884\n",
      "Iteration 375, loss = 0.48759541\n",
      "Iteration 376, loss = 0.48755146\n",
      "Iteration 377, loss = 0.48766127\n",
      "Iteration 378, loss = 0.48723800\n",
      "Iteration 379, loss = 0.48729708\n",
      "Iteration 380, loss = 0.48724426\n",
      "Iteration 381, loss = 0.48717974\n",
      "Iteration 382, loss = 0.48700193\n",
      "Iteration 383, loss = 0.48723031\n",
      "Iteration 384, loss = 0.48716729\n",
      "Iteration 385, loss = 0.48695526\n",
      "Iteration 386, loss = 0.48721071\n",
      "Iteration 387, loss = 0.48659058\n",
      "Iteration 388, loss = 0.48660420\n",
      "Iteration 389, loss = 0.48646397\n",
      "Iteration 390, loss = 0.48750996\n",
      "Iteration 391, loss = 0.48618206\n",
      "Iteration 392, loss = 0.48649968\n",
      "Iteration 393, loss = 0.48580757\n",
      "Iteration 394, loss = 0.48613870\n",
      "Iteration 395, loss = 0.48624992\n",
      "Iteration 396, loss = 0.48648070\n",
      "Iteration 397, loss = 0.48575416\n",
      "Iteration 398, loss = 0.48561347\n",
      "Iteration 399, loss = 0.48575754\n",
      "Iteration 400, loss = 0.48537704\n",
      "Iteration 401, loss = 0.48557357\n",
      "Iteration 402, loss = 0.48566656\n",
      "Iteration 403, loss = 0.48507615\n",
      "Iteration 404, loss = 0.48501633\n",
      "Iteration 405, loss = 0.48510328\n",
      "Iteration 406, loss = 0.48513597\n",
      "Iteration 407, loss = 0.48478149\n",
      "Iteration 408, loss = 0.48459356\n",
      "Iteration 409, loss = 0.48487066\n",
      "Iteration 410, loss = 0.48437616\n",
      "Iteration 411, loss = 0.48426090\n",
      "Iteration 412, loss = 0.48430797\n",
      "Iteration 413, loss = 0.48428298\n",
      "Iteration 414, loss = 0.48442995\n",
      "Iteration 415, loss = 0.48486937\n",
      "Iteration 416, loss = 0.48380118\n",
      "Iteration 417, loss = 0.48387282\n",
      "Iteration 418, loss = 0.48387343\n",
      "Iteration 419, loss = 0.48382252\n",
      "Iteration 420, loss = 0.48374301\n",
      "Iteration 421, loss = 0.48340763\n",
      "Iteration 422, loss = 0.48323075\n",
      "Iteration 423, loss = 0.48300420\n",
      "Iteration 424, loss = 0.48349219\n",
      "Iteration 425, loss = 0.48328750\n",
      "Iteration 426, loss = 0.48353271\n",
      "Iteration 427, loss = 0.48305980\n",
      "Iteration 428, loss = 0.48276346\n",
      "Iteration 429, loss = 0.48286432\n",
      "Iteration 430, loss = 0.48252854\n",
      "Iteration 431, loss = 0.48259406\n",
      "Iteration 432, loss = 0.48231630\n",
      "Iteration 433, loss = 0.48262697\n",
      "Iteration 434, loss = 0.48232658\n",
      "Iteration 435, loss = 0.48200733\n",
      "Iteration 436, loss = 0.48191040\n",
      "Iteration 437, loss = 0.48190505\n",
      "Iteration 438, loss = 0.48183113\n",
      "Iteration 439, loss = 0.48397654\n",
      "Iteration 440, loss = 0.48183371\n",
      "Iteration 441, loss = 0.48189705\n",
      "Iteration 442, loss = 0.48189513\n",
      "Iteration 443, loss = 0.48157966\n",
      "Iteration 444, loss = 0.48130404\n",
      "Iteration 445, loss = 0.48131881\n",
      "Iteration 446, loss = 0.48117739\n",
      "Iteration 447, loss = 0.48092292\n",
      "Iteration 448, loss = 0.48063806\n",
      "Iteration 449, loss = 0.48044279\n",
      "Iteration 450, loss = 0.48103386\n",
      "Iteration 451, loss = 0.48048638\n",
      "Iteration 452, loss = 0.48026190\n",
      "Iteration 453, loss = 0.48023443\n",
      "Iteration 454, loss = 0.48029804\n",
      "Iteration 455, loss = 0.47995634\n",
      "Iteration 456, loss = 0.47969791\n",
      "Iteration 457, loss = 0.47992393\n",
      "Iteration 458, loss = 0.48100383\n",
      "Iteration 459, loss = 0.48003629\n",
      "Iteration 460, loss = 0.47934885\n",
      "Iteration 461, loss = 0.47969577\n",
      "Iteration 462, loss = 0.47941430\n",
      "Iteration 463, loss = 0.47902262\n",
      "Iteration 464, loss = 0.47970322\n",
      "Iteration 465, loss = 0.47887536\n",
      "Iteration 466, loss = 0.47940847\n",
      "Iteration 467, loss = 0.47913030\n",
      "Iteration 468, loss = 0.47887552\n",
      "Iteration 469, loss = 0.47898125\n",
      "Iteration 470, loss = 0.47853477\n",
      "Iteration 471, loss = 0.47887712\n",
      "Iteration 472, loss = 0.48028775\n",
      "Iteration 473, loss = 0.47886288\n",
      "Iteration 474, loss = 0.47811405\n",
      "Iteration 475, loss = 0.47830357\n",
      "Iteration 476, loss = 0.47850985\n",
      "Iteration 477, loss = 0.47773262\n",
      "Iteration 478, loss = 0.47791147\n",
      "Iteration 479, loss = 0.47807265\n",
      "Iteration 480, loss = 0.47772098\n",
      "Iteration 481, loss = 0.47773780\n",
      "Iteration 482, loss = 0.47802710\n",
      "Iteration 483, loss = 0.47693606\n",
      "Iteration 484, loss = 0.47832843\n",
      "Iteration 485, loss = 0.47730011\n",
      "Iteration 486, loss = 0.47671945\n",
      "Iteration 487, loss = 0.47697789\n",
      "Iteration 488, loss = 0.47668341\n",
      "Iteration 489, loss = 0.47697193\n",
      "Iteration 490, loss = 0.47720243\n",
      "Iteration 491, loss = 0.47685270\n",
      "Iteration 492, loss = 0.47645103\n",
      "Iteration 493, loss = 0.47711699\n",
      "Iteration 494, loss = 0.47586842\n",
      "Iteration 495, loss = 0.47595913\n",
      "Iteration 496, loss = 0.47543378\n",
      "Iteration 497, loss = 0.47528303\n",
      "Iteration 498, loss = 0.47579950\n",
      "Iteration 499, loss = 0.47537423\n",
      "Iteration 500, loss = 0.47653406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\Pytorch-env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_mlp.fit(X_train, y_train)\n",
    "y_pred = clf_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7530050407134549"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1341,  261],\n",
       "       [ 376,  601]], dtype=int64)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      1602\n",
      "           1       0.70      0.62      0.65       977\n",
      "\n",
      "    accuracy                           0.75      2579\n",
      "   macro avg       0.74      0.73      0.73      2579\n",
      "weighted avg       0.75      0.75      0.75      2579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
